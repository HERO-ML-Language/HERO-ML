%{

open FSharp.Text.Parsing
open Source_Ref
open Error
open AST
open Lexer_Interface

let get_src_from_lexbuf (lexbuf : LexBuffer<_>) : Source_Ref =
    { File_Index = lexbuf.BufferLocalStore["file_index"] :?> int
      Start =
          { Line = lexbuf.StartPos.Line + 1
            Column = lexbuf.StartPos.Column
            Line_Offset = lexbuf.StartPos.StartOfLineAbsoluteOffset }
      End =
          { Line = lexbuf.EndPos.Line + 1
            Column = lexbuf.EndPos.Column
            Line_Offset = lexbuf.EndPos.StartOfLineAbsoluteOffset } }

let get_src_i (parseState : IParseState) index =
    // get start and end positions
    let start,end_ =
        if index = 0
        then parseState.ResultRange
        else parseState.InputRange index
    { File_Index = parseState.ParserLocalStore["file_index"] :?> int
      Start =
          { Line = start.Line + 1
            Column = start.Column
            Line_Offset = start.StartOfLineAbsoluteOffset }
      End =
          { Line = end_.Line + 1
            Column = end_.Column
            Line_Offset = end_.StartOfLineAbsoluteOffset } }

let get_src parseState = get_src_i parseState 0

let get_Lexer_Interface (parseState : IParseState) =
    parseState.ParserLocalStore["Lexer_Interface"] :?> Lexer_Interface

#if DEBUG_PARSER
let debug_parser parseState msg =
    printfn "%s: %s" (get_src parseState).Str_SE msg
#else
let debug_parser _ _ = ()
#endif

let parse_error_rich = Some (fun (ctx : ParseErrorContext<_>) ->
    let parseState = ctx.ParseState
    let lexbuf = parseState.ParserLocalStore["LexBuffer"] :?> LexBuffer<char>
    let src = get_src_from_lexbuf lexbuf
    let lexeme = (get_Lexer_Interface parseState).Get_Last_Lexeme ()
    parseState.ParserLocalStore["last_error"] <- make_error "Unexpected input: \"%s\"" lexeme src
)

let get_last_error (parseState : IParseState) =
    parseState.ParserLocalStore["last_error"] :?> Error

// generate a unique (in the whole program) ID for a variable declaration (global or local)
let gen_decl_id : unit -> Var_ID =
    let next_decl_id : Var_ID ref = ref 0
    fun () ->
        lock next_decl_id (fun () ->
            next_decl_id := !next_decl_id + 1
            !next_decl_id - 1)

// semantic value generated by the rule pre_expr
type Pre_Expr =
    | Case_Id of id : string * src : Source_Ref
    // note: single parenthesized expressions are included in this case as "one-tuples"
    | Case_Tuple of comps : Choice<Pre_Expr,Source_Ref> list * src : Source_Ref
    | Case_Half_Range of endpt : Expr * upper : bool * src : Source_Ref
    | Case_Expr of expr : Expr

let rec pre_expr_to_expr (pre_expr : Pre_Expr) : Expr =
    match pre_expr with
    // id -> variable
    | Case_Id (name,src) -> Expr (Var (name,-1,Unknown), src)
    // ( Pre_Expr ) -> Expr (single parenthesized expression)
    | Case_Tuple ([Choice1Of2 comp], _) ->
        pre_expr_to_expr comp
    | Case_Tuple ([Choice2Of2 _], _) ->
        failwith "Empty parentheses shouldn't be allowed in the grammar"
    // ( Pre_Expr,...,Pre_Expr ) -> ( Expr,...,Expr ) (bound product)
    | Case_Tuple (comps,src) ->
        let factors = comps |> List.map (
            function
            | Choice1Of2 c -> pre_expr_to_expr c
            | Choice2Of2 s -> Expr ((Error (s, "Bound products cannot have empty factors")), s))
        Expr (Func_Appl (Bound_Prod 0, factors), src)
    // a half range cannot be turned into a bound
    | Case_Half_Range (endpt,upper,src) ->
        // ..u
        if upper then
            let l_src = { src with End = src.Start }
            let l = Expr (Error (l_src, "Dense bound is missing lower endpoint"), l_src)
            Expr (Dense_Bound (l,endpt), src)
        // l..
        else
            let u_src = { src with Start = src.End }
            let u = Expr (Error (u_src, "Dense bound is missing upper endpoint"), u_src)
            Expr (Dense_Bound (endpt,u), src)
    // already an expression; copy unchanged
    | Case_Expr expr -> expr

let pre_expr_to_index_expr (pre_expr : Pre_Expr) : Index_Expr =
    match pre_expr with
    // ( Pre_Expr,...,Pre_Expr ) -> ( Expr,...,Expr )
    // note: it is okay for the "tuple" to contain only a single component here, as this is
    // interpreted as a parenthesized expression which is a one-dimensional index
    | Case_Tuple (comps,src) ->
        let comp_exprs = comps |> List.map (
            function
            | Choice1Of2 c -> pre_expr_to_expr c
            | Choice2Of2 s -> Expr ((Error (s, "Index components cannot be empty")), s))
        Index_Expr (comp_exprs,src)
    // unparenthesized expression; turn into 1D index
    | _ ->
        let expr = pre_expr_to_expr pre_expr
        Index_Expr ([expr],expr.Src)

let pre_expr_to_index_var (pre_expr : Pre_Expr) : Index_Var =
    let error_msg = "An index variable should either be a single unparenthesized identifier or a tuple of two or more identifiers"
    match pre_expr with
    | Case_Id (name,src) -> Index_Var ([name], [gen_decl_id ()], [src], src)
    // ( Pre_Expr,...,Pre_Expr ) -> ( ID,...,ID ) (at least two Pre_Expr)
    | Case_Tuple (_::_::_ as comps, src) ->
        let non_var_src = comps |> List.tryPick (
            function
            | Choice1Of2 (Case_Id _) -> None
            // anything that is not an unparenthesized ID is invalid
            | Choice1Of2 (Case_Tuple (_,src))
            | Choice1Of2 (Case_Half_Range (_,_,src))
            | Choice2Of2 src -> Some src
            | Choice1Of2 (Case_Expr expr) -> Some expr.Src)
        if non_var_src.IsSome then
            Index_Var (Error (non_var_src.Value, "Components of multidimensional index variables should be single unparenthesized identifiers"), src)
        else
            let names, comp_srcs =
                comps |> List.map (
                    function
                    | Choice1Of2 (Case_Id (name,src)) -> name, src
                    | _                               -> failwith "This can't happen")
                |> List.unzip
            let ids = List.init names.Length (ignore >> gen_decl_id)
            Index_Var (names, ids, comp_srcs, src)
    // a half range, a single parenthesized id, or any other types of expressions are invalid
    | Case_Half_Range (_,_,src) | Case_Tuple (_,src) -> Index_Var (Error (src, error_msg), src)
    | Case_Expr expr -> Index_Var (Error (expr.Src, error_msg), expr.Src)

// matches the dense bound specification of an explicit dense array
let rec (|Case_Ranges|_|) (pre_expr : Pre_Expr) : (Expr option * Expr option * Source_Ref) list option =
    match pre_expr with
    // l..
    | Case_Half_Range (l,false,src) -> Some [(Some l, None, src)]
    // ..u
    | Case_Half_Range (u,true,src) -> Some [(None, Some u, src)]
    // l..u
    | Case_Expr expr ->
        match expr.Expr' with
        | Dense_Bound (l,u) -> Some [(Some l, Some u, expr.Src)]
        | _ -> None
    // product bound or single parenthesized bound
    | Case_Tuple (_::_ as comps, src) ->
        let ranges = comps |> List.choose (
            function
            | Choice1Of2 (Case_Ranges [r]) -> Some r // a single range
            | Choice2Of2 s -> Some (None, None, s) // empty component
            | _ -> None)
        // all components are ranges
        if ranges.Length = comps.Length then
            Some ranges
        else
            None
    | _ -> None

// Derives from a list of elements of an explicit dense array definition the number of dimensions of
// the array and the "width" of each dimension. Each element of `elems' represents a segment of the
// list which is terminated by either the closing right bracket - in which case it should be the
// only segment and `ks' should be equal to [0] - or a sequence of semicolons - in which case the
// corresponding element of `ks' gives the number of semicolons.
let parse_arr_elems (elems : Expr list list) (ks : int list) : int list * Error list =
    if ks.Head = 0 then
        assert (elems.Length = 1)
        assert (ks.Length = 1)
        [elems.Head.Length], []
    else
        let rec check_bnd (errors : Error list) (to_check : int list) (exp : int list)
                          (start_srcs : Source_Ref list) (end_src : Source_Ref) =
            // if the lists are of different lengths, the longer one is implicitly truncated to the
            // length of the shorter one
            if to_check.IsEmpty || exp.IsEmpty then
                errors
            else
                let errors =
                    if to_check.Head <> exp.Head then
                        let error =
                            make_error
                                "%d elements were expected in this dimension but %d were given"
                                exp.Head to_check.Head (Source_Ref.merge start_srcs.Head end_src)
                        error::errors
                    else
                        errors
                check_bnd errors to_check.Tail exp.Tail start_srcs.Tail end_src

        let ref_fst = elems.Head.Head.Src
        ((1,[0],[ref_fst],[],[]), elems, ks)
        |||> List.fold2 (fun (num_dims,cntr,src_refs,bnd,errors) es k ->
            // `num_dims' keeps track of the number of dimensions of the array based on the segments
            // seen so far. `cntr' counts the number of "elements" (lower-dimensional sub-arrays) in
            // each dimension, with the dimensions ordered "backwards" for simplicity, i.e., with
            // the dimension that varies first as the head element, even though this is the last
            // dimension. `src_refs' keeps track of where sub-arrays of different dimensionalities
            // start in the source code so that clear error messages can be generated. `bnd'
            // collects the result, which is the number of elements in each dimension (also with the
            // dimensions ordered backwards). The first complete sub-array of each dimensionality to
            // appear when parsing from left to right sets the value to be saved in `bnd', and then
            // if something appears later in the list that doesn't match this value, an error
            // message is generated. `errors' accumulates error messages.

            // Invariants:
            // cntr.Length = src_refs.Length = num_dims
            // bnd.Length = num_dims - 1
            assert (cntr.Length = num_dims)
            assert (src_refs.Length = num_dims)
            assert (bnd.Length = num_dims - 1)
            // for each of the leading zeroes in `cntr', use the source reference for the first
            // element of `es' as the starting point for the corresponding dimensions
            let src_refs =
                match List.tryFindIndex ((<>) 0) cntr with
                | Some l -> List.replicate l (es.Head.Src) @ (List.skip l src_refs)
                | None -> assert (cntr.Length = 1); src_refs
            let end_src = (List.last es).Src
            // k semicolons terminate dimensions 0 through k-1 and increment dimension k by 1. The
            // next value of `cntr' should therefore be zeroed out in positions 0..k-1 and
            // incremented by 1 in position k. The current value of `bnd' should satisfy
            // bnd[0] = es.Length and bnd[i] = cntr[i] + 1 for i = 1,...,bnd.Length - 1, otherwise
            // the current array segment doesn't match what has appeared before it. If k >= num_dims
            // then `cntr' should first be padded with zeroes to make it length k+1 (and `num_dims' and
            // `src_refs' should also be adjusted to account for the fact that the array has k+1
            // dimensions). This is handled implicitly in the second branch below. In that case the
            // terminated dimensions that are currently included in `cntr' but not in `bnd' -
            // dimensions bnd.Length through k - should also be "commited" to `bnd'.
            if k < num_dims then
                let a, b = List.splitAt k cntr // split out the k terminated dimensions from `cntr'
                let term = es.Length :: (a.Tail |> List.map ((+) 1)) // values to check against `bnd'
                let errors = check_bnd errors term bnd src_refs end_src
                let cntr = (List.replicate k 0) @ (b.Head + 1) :: b.Tail // new value of `cntr'
                (num_dims, cntr, src_refs, bnd, errors)
            else
                let term = es.Length :: (cntr.Tail |> List.map ((+) 1)) // values to check against/commit to `bnd'
                let errors = check_bnd errors term bnd src_refs end_src
                let bnd = bnd @ (List.last term) :: (List.replicate (k - num_dims) 1) // `bnd' with new values added
                let cntr = (List.replicate k 0) @ [1] // [ 0;0;...;0;1 ] (k zeroes)
                let src_refs = (List.replicate (k+1 - num_dims) ref_fst) @ src_refs
                (k+1, cntr, src_refs, bnd, errors))
        |> fun (_,cntr,_,bnd,errors) ->
            // commit the counter for the remaining dimension and reverse the dimensions to the correct order
            (List.last cntr) :: List.rev bnd,
            errors

%}

//%define lr.type ielr
//%define lr.type canonical-lr

// keywords
%token INT FLOAT BOOL BOUND ARRAY // types
%token SKIP IF THEN ELSE WHILE DO FOREACH IN OUT // statements
%token UNDEF ERROR // "constants" for testing
%token TRUE FALSE EMPTY ALL // constants
%token FORALL // expressions
// not really keywords, but need to be treated specially by the parser
%token ID_MEMBER ID_REDUCE ID_SCAN

// punctuation
%token L_PAREN R_PAREN L_BRACE R_BRACE L_BRACK R_BRACK COMMA COLON SEMICOLON DOT_DOT

// operators
%token PLUS MINUS MUL DIV MOD L_SHIFT R_SHIFT LT LE GE GT EQ NE AND OR ARROW V_LINE

// symbolic tokens
%token <string> ID INT_LIT FLOAT_LIT

// control tokens
%token STMT_END BLOCK_BEGIN BLOCK_END EOF

// meta token representing a lexical error; not used in any production rules
%token LEX_ERROR

// special tokens that are never returned to the parser
%token <string> INT_LIT_DOT_DOT
%token NEWLINE

// to resolve ambiguities caused by half ranges ("l.." and "..u") and the keyword "in"
%nonassoc IN

// Array slicing is given lower precedence than "->" so that "forall i -> expr | bnd" is parsed as
// "(forall i -> expr) | bnd" and not "forall i -> (expr | bnd)" (slicing the result of a forall
// expression seems like it should be more common than using slicing inside the right-hand side of
// one). It is given lower precedence than ".." so that "arr | a..b" is parsed as "arr | (a..b)"
// instead of "(arr | a)..b", as the latter will never make sense.
%left V_LINE

// The "->" in forall expressions should have as low a precedence as possible so that,
// e.g., "forall i -> A[i] + B[i]" is parsed as "forall i -> (A[i] + B[i])" instead of
// "(forall i -> A[i]) + B[i]".
%nonassoc ARROW

// Since the ".." operator produces a bound, it makes the most sense to give it lower precedence
// than the arithmetic, logical and relational operators, as they are not defined for bounds.
// (Note that ".." shouldn't need an associativity, as it is a type error to write something like
// "a..b..c", but type checking is done after parsing.)
%left DOT_DOT

// standard precedence/associativity
%left OR
%left AND
%right EQ NE
%left LT LE GE GT
%left L_SHIFT R_SHIFT
%left PLUS MINUS
%left MUL DIV MOD
%nonassoc NEG

// array indexing has the highest precedence
%left L_BRACK

// to deal with the "dangling else" problem
%nonassoc NO_ELSE
%nonassoc ELSE

%start prog
%type <AST.Prog> prog
%type <AST.Expr list> L1C_expr

%%

prog : init L0_decl L1_stmt EOF { Prog ($2, $3, get_src parseState) }

// empty rule used to initialize the parser state
init :
{
    // lift over some objects from the lexer's local store to the parser's local store
    let lexbuf = parseState.ParserLocalStore["LexBuffer"] :?> LexBuffer<char>
    parseState.ParserLocalStore["Lexer_Interface"] <- lexbuf.BufferLocalStore["Lexer_Interface"]
    parseState.ParserLocalStore["file_index"] <- lexbuf.BufferLocalStore["file_index"]
}

decl
: L1C_ID COLON type stmt_end
{
    let src = get_src parseState
    List.map (fun (name,var_src) ->
        let decl_src = { src with Start = var_src.Start }
        Decl (name, gen_decl_id (), $3, decl_src)) $1
}
// error rules
| error COLON type stmt_end   { (get_Lexer_Interface parseState).Clear_Parens (); [Decl (get_last_error parseState, get_src parseState)] }
| L1C_ID COLON error stmt_end { (get_Lexer_Interface parseState).Clear_Parens (); [Decl (get_last_error parseState, get_src parseState)] }

// "int" | "float" | "bool" | "Bound" index_type | "Array" index_type type
type
: INT { Int }
| FLOAT { Float }
| BOOL { Bool }
| BOUND index_type { Type.Bound $2 }
| ARRAY index_type elem_type { Array ($3,$2) }

elem_type : type { $1 } | L_PAREN type R_PAREN { $2 }

// "int" | ("int",...,"int")
index_type : INT { 1 } | L_PAREN L2C_INT R_PAREN { $2 }

// statement/declaration terminator
stmt_end : STMT_END {} | SEMICOLON {} | SEMICOLON STMT_END {}

// The lexer always returns a `BLOCK_BEGIN' token directly after each of the keywords that begin a
// new code block - "then", "else", and (with one exception) "do". This extra dummy token is
// necessary to allow the parser, which requires one token of lookahead, a chance to call the
// appropriate methods on the lexer to tell it to update its indentation state before returning the
// first token of the code block. This logic is hidden away neatly inside the rules `block_begin'
// and `block_renew'.

block_begin : block_begin' BLOCK_BEGIN {}
block_begin' : { (get_Lexer_Interface parseState).Begin_New_Block () }

block_renew : block_renew' BLOCK_BEGIN {}
block_renew' : { (get_Lexer_Interface parseState).Renew_Block () }

stmt
// "skip" ;
: SKIP stmt_end { Stmt (Skip, get_src parseState) }
// ID[i][j]... = expr ; (zero or more indexing expressions after the ID)
| ID L0_arr_access EQ expr stmt_end { Stmt (Assign ($1,-1,$2,$4), get_src parseState) }
// "if" expr "then" block "else" block
| IF expr THEN block_begin L1_stmt else_block { Stmt (If ($2,$5,$6), get_src parseState) }
// "while" expr "do" block
| WHILE expr DO block_begin L1_stmt BLOCK_END { Stmt (While ($2,$5), get_src parseState) }
// "foreach" index_var "in" expr "do" ID[i][j]... = expr ;
| FOREACH index_var IN expr do ID L0_arr_access EQ expr stmt_end
{
    Stmt (Foreach ($2,$4,$6,-1,$7,$9), get_src parseState)
}
// "foreach" with predicate bound, where the bound implicitly reuses the variable names of the
// surrounding statement:
// "foreach" index_var : expr "do" ID[i][j]... = expr ;
| FOREACH index_var COLON expr do ID L0_arr_access EQ expr stmt_end
{
    let bound = Expr (Pred_Bound ($2,$4), get_src_i parseState 4)
    Stmt (Foreach ($2,bound,$6,-1,$7,$9), get_src parseState)
}
// "foreach" where the bound is implicitly "all"
| FOREACH index_var do ID L0_arr_access EQ expr stmt_end
{
    let bnd_src =
        let var_src = get_src_i parseState 2
        { var_src with Start = var_src.End }
    let bound = Expr (Bound_Const true, bnd_src)
    Stmt (Foreach ($2,bound,$4,-1,$5,$7), get_src parseState)
}
// output: "out" expr,...,expr ;
| OUT L0C_expr stmt_end { Stmt (Out $2, get_src parseState) }
| error
{
    debug_parser parseState "stmt : error"
    (get_Lexer_Interface parseState).Clear_Parens ()
    Stmt (get_last_error parseState, get_src parseState)
}

// instance of the "do" keyword that doesn't mark the beginning of a new block, so the subsequent
// `BLOCK_BEGIN' token is discarded
do : DO BLOCK_BEGIN {}

else_block
: BLOCK_END %prec NO_ELSE { [] } // no else block
| BLOCK_END ELSE block_begin L1_stmt BLOCK_END { $4 } // else block
| ELSE block_renew L1_stmt BLOCK_END { $3 }           // else block that doesn't begin on a new line

arr_access : L_BRACK L1C_expr R_BRACK { Index_Expr ($2, get_src parseState) }

// Expressions. To improve error handling and make for better error messages, the grammar encodes as
// few type rules as possible - i.e., it is maximally permissive regarding which types of
// expressions are allowed in which syntactical contexts - and instead leaves type checking to be
// done in a separate pass over the AST after parsing. This also makes the grammar simpler and
// reduces parser conflicts.
//
// Due to the limitations of LALR parsing, and to simplify the grammar somewhat, the rule `pre_expr'
// is defined to be a superset of all types of expressions in the language. Its semantic value is an
// object of type Pre_Expr, which contains enough information about what was parsed that it can later
// be transformed into the right AST node depending on the context (or a syntax error if it is
// inappropriate for the specific context). As can be seen below, the semantic actions for the rules
// `expr', `index_expr', and `index_var' simply "repackage" an object of type Pre_Expr.
// Syntactically, `index_expr' produces the exact same language as `expr' does, but tuples of two or
// more expressions should be represented in the AST as multidimensional indices and not product
// bounds. `index_var' produces a strict subset of the language produced by `expr' - either a single
// unparenthesized ID or a tuple of two or more (individually unparenthesized) IDs. `pre_expr' also
// includes dense bounds that are either half ranges ("l.." and "..u") or tuples of two or more
// (half) ranges where some or all components of the tuple can be left empty. These types of partial
// dense bounds are used in the preamble of explicit dense arrays, but are not allowed in any other
// places where a dense bound is accepted.

expr : pre_expr { pre_expr_to_expr $1 }

// expr | (expr,...,expr)
index_expr : pre_expr { pre_expr_to_index_expr $1 }

// ID | (ID,...,ID)
index_var : pre_expr { pre_expr_to_index_var $1 }

pre_expr
: ID { Case_Id ($1, get_src parseState) }
// tuples (including "one-tuples", i.e., single parenthesized expressions)
| L_PAREN pre_expr R_PAREN { Case_Tuple ([Choice1Of2 $2], get_src parseState) }
| L_PAREN L2C_tuple_comp R_PAREN { Case_Tuple ($2, get_src parseState) }
| L_PAREN error R_PAREN
{
    let expr = Expr (get_last_error parseState, get_src_i parseState 2)
    Case_Tuple ([Choice1Of2 (Case_Expr expr)], get_src parseState)
}
// half ranges: "l.." or "..u"
| expr DOT_DOT { Case_Half_Range ($1,false,get_src parseState) }
| DOT_DOT expr { Case_Half_Range ($2,true, get_src parseState) }
// expressions
| pre_expr' { Case_Expr $1 }

// at least a source reference is saved for empty tuple components
tuple_comp : { Choice2Of2 (get_src_i parseState 0) } | pre_expr { Choice1Of2 $1 }

pre_expr'
// array access: array [ expr,...,expr ]
: expr arr_access { Expr (Array_Access ($1,$2), get_src parseState) }
// input: "in" type
| IN type { Expr (In $2, get_src parseState) }

// special constants which are not available in the core language but can be used as extensions for
// testing purposes
| UNDEF type { Expr (Undef_Const $2, get_src parseState) }
| UNDEF      { Expr (Undef_Const Type.Int, get_src parseState) } // default type int
| ERROR type { Expr (Error_Const $2, get_src parseState) }
| ERROR      { Expr (Error_Const Type.Int, get_src parseState) } // default type int

// Exclusively numerical expressions (int and float) -------------------------------------
| INT_LIT { Expr (Int_Const (int $1), get_src parseState) }
| FLOAT_LIT { Expr (Float_Const (float $1), get_src parseState) }
| MINUS expr %prec NEG { Expr (Func_Appl (Func.Neg_I, [$2]), get_src parseState) }
| expr PLUS  expr   { Expr (Func_Appl (Func.Add_I,   [$1;$3]), get_src parseState) }
| expr MINUS expr   { Expr (Func_Appl (Func.Sub_I,   [$1;$3]), get_src parseState) }
| expr MUL   expr   { Expr (Func_Appl (Func.Mul_I,   [$1;$3]), get_src parseState) }
| expr DIV   expr   { Expr (Func_Appl (Func.Div_I,   [$1;$3]), get_src parseState) }
| expr MOD   expr   { Expr (Func_Appl (Func.Mod,     [$1;$3]), get_src parseState) }
| expr L_SHIFT expr { Expr (Func_Appl (Func.L_Shift, [$1;$3]), get_src parseState) }
| expr R_SHIFT expr { Expr (Func_Appl (Func.R_Shift, [$1;$3]), get_src parseState) }

// Exclusively boolean expressions --------------------------------------------------
| TRUE  { Expr (Bool_Const true,  get_src parseState) }
| FALSE { Expr (Bool_Const false, get_src parseState) }
| expr LT  expr { Expr (Func_Appl (Func.LT_I, [$1;$3]), get_src parseState) }
| expr LE  expr { Expr (Func_Appl (Func.LE_I, [$1;$3]), get_src parseState) }
| expr GE  expr { Expr (Func_Appl (Func.GE_I, [$1;$3]), get_src parseState) }
| expr GT  expr { Expr (Func_Appl (Func.GT_I, [$1;$3]), get_src parseState) }
| expr EQ  expr { Expr (Func_Appl (Func.Eq_I, [$1;$3]), get_src parseState) }
| expr NE  expr { Expr (Func_Appl (Func.NE_I, [$1;$3]), get_src parseState) }
| expr AND expr { Expr (Func_Appl (Func.And,  [$1;$3]), get_src parseState) }
| expr OR  expr { Expr (Func_Appl (Func.Or,   [$1;$3]), get_src parseState) }

// Exclusively bound-valued expressions ------------------------------------------------
| EMPTY { Expr (Bound_Const false, get_src parseState) }
| ALL { Expr (Bound_Const true, get_src parseState) }
// dense one-dimensional bound: expr ".." expr
| expr DOT_DOT expr { Expr (Dense_Bound ($1,$3), get_src parseState) }
// sparse bound: { index_expr,...,index_expr }
| L_BRACE L1C_index_expr R_BRACE { Expr (Sparse_Bound $2, get_src parseState) }
// predicate bound: { index_var : expr }
| L_BRACE index_var COLON expr R_BRACE { Expr (Pred_Bound ($2,$4), get_src parseState) }
// error rules
| L_BRACE error R_BRACE { Expr (get_last_error parseState, get_src parseState) }

// Exclusively array-valued expressions -------------------------------------------------
// Since the parser has only a single token of lookahead, some of these rules are formulated
// somewhat awkwardly because longer prefixes of tokens are required to distinguish between the
// different kinds of array expressions. Below are the different cases for the prefixes, with
// `bound' representing a (partial) dense bound and `C' representing either a comma or a sequence of
// semicolons:
//
// 1. [ expr        ]                               (single-element dense array with implicit bound)
// 2. [ expr        C ...                           (dense array with implicit bound)
// 3. [ expr        : index_var in ...              (array comprehension)
// 4. [ expr        : index_var :  ...              (array comprehension using syntactic sugar)
// 5. [ bound       : expr      ]                   (single-element dense array with explicit bound)
// 6. [ bound       : expr      C  expr       C     (dense array with explicit bound)
// 7. [ index_expr  : expr      ]                   (single-element sparse array)
// 8. [ index_expr  : expr      C  index_expr : ... (sparse array)
//
// The first instance of `expr', `bound', or `index_expr' in each case above needs to be parsed as a
// `pre_expr' and then turned into the correct form in the semantic action, after the full prefix
// has been parsed. To distinguish between cases (5) and (7), a pattern match is required on the
// `pre_expr'. Also, the `C' in case (8) should always be a comma, so this has to be checked in the
// semantic action as well.
//
// explicit dense array with implicit 0-based index ranges (cases (1) and (2)):
// [ expr,...,expr ;; ... ]
| L_BRACK arr_elems R_BRACK
{
    let bound, errors =
        let impl_bnd, errors = parse_arr_elems <|| $2
        // a zero constant with a dummy source reference to the position right before the first element
        let ``0`` =
            let s = get_src_i parseState 2
            let dummy_src = { s with End = s.Start }
            Expr (Int_Const 0, dummy_src)
        impl_bnd |> List.map (fun n -> (``0``, None, n-1)),
        errors
    let elems =
        if errors.IsEmpty then
            List.concat (fst $2)
        else
            // for lack of a better place, add the errors as dummy expression to the list of elements (TODO:)
            (List.concat (fst $2)) @ (errors |> List.map (fun e -> Expr (e,e.Src)))
    Expr (Dense_Array (bound,elems), get_src parseState)
}
// array comprehension (case (3)):
// [ expr : index_var "in" expr ]
| L_BRACK pre_expr COLON index_var IN expr R_BRACK
{
    let elem_expr = pre_expr_to_expr $2
    Expr (Array_Compr ($4,elem_expr,$6), get_src parseState)
}
// syntactic sugar for array comprehension with a predicate bound, where the bound implicitly reuses
// the variable names of the surrounding expression (case (4)):
// [ expr : index_var : expr ]
| L_BRACK pre_expr COLON index_var COLON expr R_BRACK
{
    let elem_expr = pre_expr_to_expr $2
    let bound = Expr (Pred_Bound ($4,$6), get_src_i parseState 6)
    Expr (Array_Compr ($4,elem_expr,bound), get_src parseState)
}
// an array with a single element, in one of the following two forms (case (5) or (7)):
// dense 1D array: [ l..u : expr ] (where one of l or u might be left out)
// sparse array:   [ index_expr : expr ]
| L_BRACK pre_expr COLON expr R_BRACK
{
    match $2 with
    // dense array with bound l..u or l..
    | Case_Ranges [(Some l, u, src)] ->
        Expr (Dense_Array ([(l,u,0)], [$4]), get_src parseState)
    // dense array with bound ..u
    | Case_Ranges [(None, Some u, src)] ->
        Expr (Dense_Array ([(u,None,0)], [$4]), get_src parseState)
    // sparse array (or error if the pre_expr cannot be interpreted as an index expression)
    | _ ->
        let index_expr = pre_expr_to_index_expr $2
        Expr (Sparse_Array ([index_expr], [$4]), get_src parseState)
}
// dense array with explicit bound and two or more elements (case (6)):
// [ bound : expr, expr, ... ]
| L_BRACK pre_expr COLON expr COMMA_or_L1_SEMICOLON arr_elems R_BRACK
{
    let elems', ks' = $6
    let elems, ks =
        if $5 = 0 then ($4 :: elems'.Head) :: elems'.Tail, ks'
        else [$4]::elems', $5::ks'
    let bound, errors =
        // a zero constant in case it's needed, with a dummy source reference to the position right
        // before the first element
        let ``0`` =
            let s = get_src_i parseState 4
            let dummy_src = { s with End = s.Start }
            Expr (Int_Const 0, dummy_src)
        let impl_bnd, errors = parse_arr_elems elems ks
        match $2 with
        | Case_Ranges expl_bnd ->
            let expl_bnd, impl_bnd, errors =
                let expl_dims = expl_bnd.Length
                let impl_dims = impl_bnd.Length
                if expl_dims <> impl_dims then
                    let error =
                        make_error
                            "The given bound has %d dimensions, but the list of elements \
                             indicates that the array has %d dimensions"
                             expl_dims impl_dims (get_src_i parseState 2)
                    List.truncate impl_dims expl_bnd,
                    List.truncate expl_dims impl_bnd,
                    error :: errors
                else
                    expl_bnd, impl_bnd, errors
            (expl_bnd, impl_bnd) ||> List.map2 (fun e i ->
                match e with
                | (None,   None,   _) -> (``0``, None, i-1)
                | (Some l, None,   _) -> (l, None, i-1)
                | (None,   Some u, _) -> (u, None, -i+1)
                | (Some l, Some u, _) -> (l, Some u, i-1)),
            errors
        | _ ->
            // wrong format on the given bound; generate an error message and create a zero-based
            // dense bound that matches the element list as a placeholder
            impl_bnd |> List.map (fun n -> (``0``, None, n-1)),
            Error (get_src_i parseState 2, "Expected a dense bound") :: errors
    let elems = 
        if errors.IsEmpty then
            List.concat elems
        else
            // for lack of a better place, add the errors as dummy expression to the list of elements (TODO:)
            (List.concat elems) @ (errors |> List.map (fun e -> Expr (e, e.Src)))
    Expr (Dense_Array (bound,elems), get_src parseState)
}
// sparse array with two or more elements (case (8)):
// [ index_expr : expr, ..., index_expr : expr ]
| L_BRACK pre_expr COLON expr COMMA_or_L1_SEMICOLON L1C_index_expr_COLON_expr R_BRACK
{
    let errors =
        // should be a comma
        if $5 <> 0 then
            let error_src = get_src_i parseState 5
            [ Expr (Error (error_src, "Elements of explicit sparse arrays should be separated using commas"), error_src) ]
        else []
    let idcs', elems' = List.unzip $6
    let idcs = (pre_expr_to_index_expr $2) :: idcs'
    let elems = $4 :: elems' @ errors
    Expr (Sparse_Array (idcs,elems), get_src parseState)
}
// error rule
| L_BRACK error R_BRACK { Expr (get_last_error parseState, get_src parseState) }

// forall index_var -> expr
| FORALL index_var ARROW expr { Expr (Forall ($2,$4), get_src parseState) }
// array | bound
| expr V_LINE expr { Expr (Func_Appl (Slice_Array (Unknown,0), [$1;$3]), get_src parseState) }

// Function calls: ID ( ... ) -------------------------------------
| func_id L_PAREN L1C_expr R_PAREN
{
    let src = get_src parseState
    match $1 with
    | Choice1Of2 func ->
        // we leave it to the type analysis to check the number of arguments
        Expr (Func_Appl (func,$3), src)
    | Choice2Of2 func_id ->
        Expr (make_error "Undefined function \"%s\"" func_id (get_src_i parseState 1), src)
}
| ID_MEMBER L_PAREN index_expr COMMA expr R_PAREN
{
    Expr (Member_Func_Appl ($3.Num_Dims,$3,$5), get_src parseState)
}
| ID_REDUCE L_PAREN arg_op COMMA expr R_PAREN
{
    let src = get_src parseState
    match $3 with
    | Choice1Of2 arg_op ->
        Expr (HO_Func_Appl (HO_Func.Reduce (Unknown,0), arg_op, $5), src)
    | Choice2Of2 arg_op_lexeme ->
        Expr (make_error "Undefined function \"%s\"" arg_op_lexeme (get_src_i parseState 3), src)
}
| ID_SCAN L_PAREN arg_op COMMA expr R_PAREN
{
    let src = get_src parseState
    match $3 with
    | Choice1Of2 arg_op ->
        Expr (HO_Func_Appl (HO_Func.Scan (Unknown,0), arg_op, $5), src)
    | Choice2Of2 arg_op_lexeme ->
        Expr (make_error "Undefined function \"%s\"" arg_op_lexeme (get_src_i parseState 3), src)
}
// error rules
| func_id L_PAREN error R_PAREN { Expr (get_last_error parseState, get_src parseState) }
| ID_MEMBER L_PAREN error R_PAREN { Expr (get_last_error parseState, get_src parseState) }
| ID_REDUCE L_PAREN error R_PAREN { Expr (get_last_error parseState, get_src parseState) }
| ID_SCAN L_PAREN error R_PAREN { Expr (get_last_error parseState, get_src parseState) }

COMMA_or_L1_SEMICOLON : COMMA { 0 } | L1_SEMICOLON { $1 }

arr_elems : arr_elems' L0_SEMICOLON
{
    let elems, ks = $1
    // the last sequence of semicolons is extended if necessary to the same length as the longest
    // such sequence encountered earlier
    let max_k = List.max ($2::ks)
    List.rev elems,
    List.rev (max_k::ks)
}

arr_elems' : L1C_expr { [$1], [] } | arr_elems' L1_SEMICOLON L1C_expr { $3::(fst $1), $2::(snd $1) }

func_id
: ID
{
    match $1 with
    | "not"         -> Choice1Of2 Func.Not
    | "isDef"       -> Choice1Of2 (Func.Is_Def Unknown)
    | "bound"       -> Choice1Of2 (Func.Bound (Unknown,0))
    | "join"        -> Choice1Of2 (Func.Join        0)
    | "meet"        -> Choice1Of2 (Func.Meet        0)
    | "isDense"     -> Choice1Of2 (Func.Is_Dense     0)
    | "isSparse"    -> Choice1Of2 (Func.Is_Sparse    0)
    | "isPredicate" -> Choice1Of2 (Func.Is_Predicate 0)
    | "isProduct"   -> Choice1Of2 (Func.Is_Product   0)
    | "finite"      -> Choice1Of2 (Func.Is_Finite    0)
    | "size"        -> Choice1Of2 (Func.Size        0)
    | "exp"         -> Choice1Of2 Func.Exp
    | "sqrt"        -> Choice1Of2 Func.Sqrt
    | _             -> Choice2Of2 $1
}
| INT   { Choice1Of2 Func.Cast_F_I }
| FLOAT { Choice1Of2 Func.Cast_I_F }
| IF    { Choice1Of2 (Func.If Unknown) }

arg_op
: PLUS  { Choice1Of2 Func.Add_I }
| MINUS { Choice1Of2 Func.Sub_I }
| MUL   { Choice1Of2 Func.Mul_I }
| DIV   { Choice1Of2 Func.Div_I }
| AND   { Choice1Of2 Func.And }
| OR    { Choice1Of2 Func.Or }
| func_id { $1 }

// Below follow all "list" production rules. The following naming convention is used:
// The initial "L" stands for "list", then comes a number stating the minimum number elements in the
// list. This is followed by a "C" if the elements are to be separated by commas. After the
// underscore comes the element (a terminal or non-terminal symbol) that is being repeated. For
// efficiency, any F# lists being returned as semantic values are constructed in reverse order
// (using the rules that have a ' suffix to their name), and then reversed by the "wrapper"
// production rule as a last step.

L0_decl : { [] } | L0_decl decl { $1 @ $2 }

L1_stmt : L1_stmt' { List.rev $1 }
L1_stmt' : stmt { [$1] } | L1_stmt' stmt { $2::$1 }

L1C_ID : L1C_ID' { List.rev $1 }
L1C_ID'
: ID               { [($1, get_src_i parseState 1)] }
| L1C_ID' COMMA ID { ($3, get_src_i parseState 3)::$1 }

L2C_INT : INT COMMA INT { 2 } | L2C_INT COMMA INT { $1 + 1 }

L0_arr_access : L0_arr_access' { List.rev $1 }
L0_arr_access' : { [] } | L0_arr_access' arr_access { $2::$1 }

L1C_expr : L1C_expr' { List.rev $1 }
// the first element of the expression list is parsed as a pre_expr to resolve some reduce/reduce
// conflicts in the grammar
L1C_expr' : pre_expr { [pre_expr_to_expr $1] } | L1C_expr' COMMA expr { $3::$1 }
L0C_expr : { [] } | L1C_expr { $1 }

L1C_index_expr : L1C_index_expr' { List.rev $1 }
L1C_index_expr' : index_expr { [$1] } | L1C_index_expr' COMMA index_expr { $3::$1 }

L1C_index_expr_COLON_expr : L1C_index_expr_COLON_expr' { List.rev $1 }
L1C_index_expr_COLON_expr'
: index_expr COLON expr { [($1,$3)] }
| L1C_index_expr_COLON_expr' COMMA index_expr COLON expr { ($3,$5)::$1 }

L2C_tuple_comp : L2C_tuple_comp' { List.rev $1 }
L2C_tuple_comp' : tuple_comp COMMA tuple_comp { [$3;$1] } | L2C_tuple_comp' COMMA tuple_comp { $3::$1 }

L1_SEMICOLON : SEMICOLON { 1 } | L1_SEMICOLON SEMICOLON { $1 + 1 }
L0_SEMICOLON : { 0 } | L1_SEMICOLON { $1 }
